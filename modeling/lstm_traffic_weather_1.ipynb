{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "import keras\n",
    "from keras.utils import pad_sequences\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects: run the code on lstm_traffic_only_1 to generate the csv info\n",
    "\n",
    "traffic_df = pd.read_csv(\"../data/traffic_pre_lstm.csv\")\n",
    "traffic_df['timestamp'] = pd.to_datetime(traffic_df['timestamp'])\n",
    "traffic_df.set_index('timestamp', inplace=True)\n",
    "traffic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(\"../data/aarhus_weather_data_combined.csv\")\n",
    "weather_df[\"Datetime\"] = pd.to_datetime(weather_df[\"Datetime\"])\n",
    "weather_df.set_index(\"Datetime\", inplace=True, drop=True)\n",
    "\n",
    "# merge with a complete timestamp index\n",
    "timestamp_index = pd.DataFrame({\"timestamp\": pd.date_range(pd.to_datetime(\n",
    "    weather_df.index.min()), pd.to_datetime(weather_df.index.max()), freq=\"5min\").to_list()})\n",
    "\n",
    "weather_df = timestamp_index.merge(\n",
    "    weather_df,\n",
    "    how=\"left\",\n",
    "    left_on=\"timestamp\",\n",
    "    right_index=True\n",
    ")\n",
    "weather_df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "# impute missing values using linear interpolation\n",
    "weather_df.interpolate(method=\"linear\", inplace=True)\n",
    "\n",
    "\n",
    "weather_features = [\"pressurem\", \"tempm\", \"vism\", \"wspdm\"]\n",
    "\n",
    "combined_weather_traffic = traffic_df.merge(\n",
    "    weather_df[weather_features],\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "# remove rows at the end without occupancy data\n",
    "combined_weather_traffic = combined_weather_traffic[combined_weather_traffic[\"wspdm\"].notna()]\n",
    "\n",
    "combined_weather_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sample = combined_weather_traffic[100:14000]\n",
    "validation_sample = combined_weather_traffic[14001:]\n",
    "\n",
    "validation_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_training_set(training_sample, seq_length, pred_horizon, input_features, output_features):\n",
    "    seq_arrays = []\n",
    "    seq_labs = []\n",
    "    for i in range(training_sample.shape[0] - seq_length - pred_horizon):\n",
    "        seq_arrays.append(training_sample.iloc[i:seq_length+i, :input_features].to_numpy())\n",
    "        seq_labs.append(training_sample.iloc[seq_length+pred_horizon+i, :output_features])\n",
    "\n",
    "    seq_arrays = np.array(seq_arrays, dtype=object).astype(np.float32)\n",
    "    seq_labs = np.array(seq_labs, dtype=object).astype(np.float32)\n",
    "    return seq_arrays, seq_labs\n",
    "\n",
    "# create validation dataset\n",
    "def create_validation_set(validation_sample, seq_length, pred_horizon, input_features, output_features):\n",
    "    val_arrays = []\n",
    "    val_labs = []\n",
    "    for i in range(validation_sample.shape[0] - seq_length - pred_horizon):\n",
    "        if i < seq_length:\n",
    "            val_arrays.append(validation_sample.iloc[:(i+1), :input_features].to_numpy())\n",
    "            val_labs.append(validation_sample.iloc[:(i+pred_horizon+1), :output_features].to_numpy()[-1])\n",
    "        else:\n",
    "            val_arrays.append(validation_sample.iloc[i:seq_length+i, :input_features].to_numpy())\n",
    "            val_labs.append(validation_sample.iloc[seq_length+i+pred_horizon, :output_features])\n",
    "\n",
    "    val_arrays = pad_sequences(val_arrays, padding='pre', dtype=object).astype(np.float32)\n",
    "    val_labs = np.array(val_labs, dtype=object).astype(np.float32)\n",
    "    return val_arrays, val_labs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set predictive horizon and sequence length\n",
    "ph = 5\n",
    "seq_length = 12\n",
    "\n",
    "# features to randomly sample without replacement\n",
    "# must be a value between 1 to 453, inclusive \n",
    "\n",
    "input_features = 453 \n",
    "output_features = 449\n",
    "\n",
    "sensor = pd.Series(training_sample.columns).sample(\n",
    "    input_features, replace=False).sort_values().to_list()\n",
    "\n",
    "\n",
    "seq_arrays, seq_labs = create_sequence_training_set(training_sample, seq_length, ph,input_features, output_features)\n",
    "\n",
    "val_arrays, val_labs = create_validation_set(validation_sample, seq_length, ph, input_features, output_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(model_path, seq_length, seq_arrays, seq_labs, input_features, output_features):\n",
    "# define path to save model\n",
    "    model_path = model_path\n",
    "\n",
    "    # build the network\n",
    "    output_size = output_features\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_shape=(seq_length, input_features), \n",
    "        units=100, activation=\"relu\", return_sequences=True))\n",
    "    model.add(Dropout(0.025))\n",
    "\n",
    "    model.add(LSTM(units=64, activation=\"relu\", return_sequences=True))\n",
    "    model.add(Dropout(0.025))\n",
    "    model.add(LSTM( units=32, activation=\"relu\", return_sequences=False))\n",
    "    model.add(Dense(units=output_size, activation=\"linear\"))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # fit the network\n",
    "    history = model.fit(seq_arrays,\n",
    "                    seq_labs,\n",
    "                    epochs=1000,\n",
    "                    batch_size=80,\n",
    "                    validation_split=0.05,\n",
    "                    verbose=2,\n",
    "                    callbacks=[\n",
    "                        keras.callbacks.EarlyStopping(\n",
    "                            monitor='val_loss',\n",
    "                            min_delta=0.1,\n",
    "                            patience=5,\n",
    "                            verbose=0,\n",
    "                            mode='min'),\n",
    "                        keras.callbacks.ModelCheckpoint(\n",
    "                            model_path,\n",
    "                            monitor='val_loss',\n",
    "                            save_best_only=True,\n",
    "                            mode='min',\n",
    "                            verbose=0)\n",
    "                    ])\n",
    "\n",
    "    return model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_lstm_model('lstm_traffic_weather.keras',\n",
    "                                  seq_length,\n",
    "                                  seq_arrays,\n",
    "                                  seq_labs,\n",
    "                                  input_features, \n",
    "                                  output_features)\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_history_loss(history, title):\n",
    "    # summarize history for Loss/MSE\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "summarize_history_loss(history, \"Traffic + Weather model loss/mse\")\n",
    "\n",
    "scores_test = model.evaluate(val_arrays, val_labs, verbose=2)\n",
    "print('\\nMSE: {}'.format(scores_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_across_network(model, val_arrays, val_labs, title):\n",
    "    y_pred_test = model.predict(val_arrays)\n",
    "    y_true_test = val_labs\n",
    "\n",
    "    # aggregating for easier visualization\n",
    "    y_pred_dv = [row.sum() for row in y_pred_test]\n",
    "    y_true_dv = [row.sum() for row in y_true_test]\n",
    "\n",
    "    start = 1000\n",
    "    ts = 1000\n",
    "\n",
    "    plt.plot(y_pred_dv[start:start+ts], label='Predicted Value')\n",
    "    plt.plot(y_true_dv[start:start+ts], label='Actual Value')\n",
    "    plt.title(title,\n",
    "            fontsize=22, fontweight='bold')\n",
    "    plt.ylabel('value')\n",
    "    plt.xlabel('row')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_prediction_across_network(model, val_arrays, val_labs, 'Sum of Average Speed Across Network')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usd_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
